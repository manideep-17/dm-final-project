{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install imbalanced-learn\n",
    "!pip install imbalanced-learn --quiet\n",
    "!pip install pandas --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install seaborn --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install xgboost --quiet\n",
    "!pip install lightgbm --quiet\n",
    "!pip install catboost --quiet\n",
    "!pip install optuna --quiet\n",
    "print(\"Installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing Libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model Selection and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-saved training and validation sets\n",
    "X_train_resampled = pd.read_csv('X_train_resampled.csv')\n",
    "y_train_resampled = pd.read_csv('y_train_resampled.csv').squeeze()  # Squeeze to convert to Series if needed\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "y_val = pd.read_csv('y_val.csv').squeeze()\n",
    "\n",
    "# Loading test set\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "# Loading submission template\n",
    "submission_template = pd.read_csv('submission_template.csv')\n",
    "\n",
    "print(\"DataFrames loaded from CSV successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the model with new hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=7,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.7978109153629405,\n",
    "    scale_pos_weight=10,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the resampled training data\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "y_prob = xgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"XGBoost with Updated Hyperparameters\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Step 6: Run probability predictions on the test set\n",
    "test_probabilities = xgb_model.predict_proba(X_test)[:, 1]  # Select probability for the positive class (isFraud)\n",
    "\n",
    "# Step 7: Prepare submission DataFrame with probabilities\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities\n",
    "\n",
    "# Step 8: Save predictions to a CSV file\n",
    "submission.to_csv('best/submission_xgb_best.csv', index=False)\n",
    "\n",
    "print(\"Probability predictions saved to submission_xgb_best.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight=None, random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "y_prob = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Step 6: Run predictions on the test set\n",
    "test_probabilities = rf.predict_proba(X_test)[:, 1]  # Select probability for the positive class (isFraud)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities  # Assign probabilities\n",
    "\n",
    "# Step 8: Save predictions to a CSV file\n",
    "submission.to_csv('best/submission_rfc_best.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to submission_rfc_best.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# params = {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cholesky', 'class_weight': None, 'max_iter': 1000, 'tol': 1e-4}\n",
    "\n",
    "params = {'solver': 'newton-cholesky', 'penalty': 'l2', 'C': 0.04783940335702436, 'tol': 1.3833218995442702e-05, 'max_iter': 631}\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42, **params)\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Validation predictions and evaluation\n",
    "y_pred = log_reg.predict(X_val)\n",
    "y_prob = log_reg.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val, y_prob)\n",
    "\n",
    "test_probabilities = log_reg.predict_proba(X_test)\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities[:, 1]  # Assuming 'isFraud' is the positive class\n",
    "\n",
    "# Save the submission file for each combination\n",
    "submission.to_csv(f'best/submission_best_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "    \n",
    "# params={'learning_rate': 0.05, 'iterations': 500, 'depth': 8, 'l2_leaf_reg': 5, 'bagging_temperature': 0.5, 'random_strength': 2, 'scale_pos_weight': 10}\n",
    "\n",
    "params = {'learning_rate': 0.14501102083693077, 'iterations': 751, 'depth': 8, 'l2_leaf_reg': 5.595512756503533, 'bagging_temperature': 1.0454087496215603, 'random_strength': 1.008663275116376, 'scale_pos_weight': 8.064297059289366, \n",
    "           'random_seed': 42, 'verbose': 0}\n",
    "# Initialize the CatBoost model with current parameters\n",
    "catboost_model = CatBoostClassifier(\n",
    "    **params,\n",
    "    eval_metric='AUC'\n",
    ")\n",
    "\n",
    "    # Fit the model on the resampled training data\n",
    "catboost_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = catboost_model.predict(X_val)\n",
    "y_prob = catboost_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"Parameters:\", params)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\\n\")\n",
    "\n",
    "# Step 6: Predict probabilities on the test set\n",
    "test_probabilities = catboost_model.predict_proba(X_test)\n",
    "\n",
    "# Step 7: Prepare submission DataFrame with probabilities for the positive class\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities[:, 1]  # Assuming 'isFraud' is the positive class\n",
    "\n",
    "# Step 8: Save predictions to a CSV file with a unique name for each parameter set\n",
    "submission.to_csv(f'best/submission_catboost_best.csv', index=False)\n",
    "print(\"DOne! , saved\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# params = {'learning_rate': 0.05, 'n_estimators': 500, 'max_depth': 15, 'num_leaves': 50, 'min_child_samples': 10,\n",
    " # 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_lambda': 5, 'reg_alpha': 0.1, 'scale_pos_weight': 10}\n",
    "params = {'learning_rate': 0.09906417236746058, 'n_estimators': 454, 'max_depth': 10, 'num_leaves': 46, \n",
    "          'min_child_samples': 47, 'subsample': 0.8592558986910852, 'colsample_bytree': 0.7443545915949523, \n",
    "          'reg_lambda': 1.7308107963855828, 'reg_alpha': 0.24840082175007047, 'scale_pos_weight': 2.458598065242119}\n",
    "\n",
    "# Initialize the LGBMClassifier with current parameters\n",
    "lgbm_model = LGBMClassifier(\n",
    "    **params,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the resampled training data\n",
    "lgbm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = lgbm_model.predict(X_val)\n",
    "y_prob = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Parameters:\", params)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\\n\")\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "test_probabilities = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities  # Save probabilities as predictions\n",
    "\n",
    "# Save predictions to a CSV file with a unique name for each parameter set\n",
    "submission.to_csv(f'best/submission_lgbm_best.csv', index=False)\n",
    "\n",
    "print(\"Probability predictions saved to submission_lgbm_best.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import optuna\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Pre-trained base models\n",
    "pretrained_base_models = [\n",
    "    ('lgbm', lgbm_model),    # Pre-trained LightGBM\n",
    "    ('catboost', catboost_model),  # Pre-trained CatBoost\n",
    "]\n",
    "\n",
    "# Create timestamped folder for saving results\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_folder = f\"stacking_simple_bayesian_meta_results_{timestamp}\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Set up logging\n",
    "log_file = os.path.join(output_folder, \"log.txt\")\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Define the Optuna objective function for meta-model tuning\n",
    "def objective(trial):\n",
    "    # Hyperparameter search space for the meta-model\n",
    "    # Extensive hyperparameter set for Logistic Regression\n",
    "    solver = trial.suggest_categorical('solver', ['newton-cholesky', 'sag', 'saga'])\n",
    "    penalty = trial.suggest_categorical('penalty', ['l2', None, 'l1'])\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e3)\n",
    "    tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "    # Compatibility checks for solver and penalty\n",
    "    if solver == 'newton-cholesky' and penalty not in ['l2', 'none']:\n",
    "        logger.warning(f\"Trial {trial.number}: Invalid combination (solver={solver}, penalty={penalty}). Pruning trial.\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    if solver == 'sag' and penalty != 'l2':\n",
    "        logger.warning(f\"Trial {trial.number}: Invalid combination (solver={solver}, penalty={penalty}). Pruning trial.\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    meta_model = LogisticRegression(\n",
    "        solver=solver,\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        tol=tol,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Stacking classifier with pre-trained base models\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=pretrained_base_models,\n",
    "        final_estimator=meta_model,\n",
    "        cv=3  # Cross-validation for meta-model\n",
    "    )\n",
    "    logger.info(f\"Trial {trial.number}: Starting with meta-model parameters: solver={solver}, penalty={penalty}, C={C}, tol={tol}, max_iter={max_iter}\")\n",
    "\n",
    "    # Stratified K-Fold Cross-Validation\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    fold_aucs = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_resampled, y_train_resampled), 1):\n",
    "        logger.info(f\"  Fold {fold}: Training StackingClassifier...\")\n",
    "        X_train_fold, X_val_fold = X_train_resampled.iloc[train_idx], X_train_resampled.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_resampled.iloc[train_idx], y_train_resampled.iloc[val_idx]\n",
    "\n",
    "        # Train Stacking Classifier\n",
    "        stacking_clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict probabilities for validation set\n",
    "        y_prob = stacking_clf.predict_proba(X_val_fold)[:, 1]\n",
    "        fold_auc = roc_auc_score(y_val_fold, y_prob)\n",
    "        fold_aucs.append(fold_auc)\n",
    "        logger.info(f\"  Fold {fold}: AUC-ROC = {fold_auc:.4f}\")\n",
    "\n",
    "    # Calculate mean AUC-ROC across folds\n",
    "    mean_auc = np.mean(fold_aucs)\n",
    "    logger.info(f\"Trial {trial.number}: Mean AUC-ROC across folds = {mean_auc:.4f}\")\n",
    "\n",
    "    # Save predictions on test set for this trial\n",
    "    test_probabilities = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "    submission = submission_template.copy()\n",
    "    submission['isFraud'] = test_probabilities\n",
    "    submission_file = os.path.join(output_folder, f\"submission_trial_{trial.number}.csv\")\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "    logger.info(f\"Trial {trial.number}: Submission saved to {submission_file}\")\n",
    "\n",
    "    # Store results\n",
    "    trial.set_user_attr(\"fold_aucs\", fold_aucs)\n",
    "    trial.set_user_attr(\"mean_auc\", mean_auc)\n",
    "    trial.set_user_attr(\"meta_params\", {\n",
    "        'solver': solver,\n",
    "        'penalty': penalty,\n",
    "        'C': C,\n",
    "        'tol': tol,\n",
    "        'max_iter': max_iter\n",
    "    })\n",
    "\n",
    "    return mean_auc\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "logger.info(\"Starting Bayesian optimization with Optuna...\")\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)  # Adjust number of trials as needed\n",
    "\n",
    "# Save all trials results\n",
    "all_trials = []\n",
    "for trial in study.trials:\n",
    "    all_trials.append({\n",
    "        \"trial_number\": trial.number,\n",
    "        \"meta_params\": trial.user_attrs[\"meta_params\"],\n",
    "        \"mean_auc\": trial.user_attrs[\"mean_auc\"],\n",
    "        \"fold_aucs\": trial.user_attrs[\"fold_aucs\"]\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_trials)\n",
    "results_file = os.path.join(output_folder, \"all_trials_results.csv\")\n",
    "results_df.to_csv(results_file, index=False)\n",
    "logger.info(f\"All trial results saved to {results_file}\")\n",
    "\n",
    "# Print and save top 3 models\n",
    "top_3 = results_df.sort_values(\"mean_auc\", ascending=False).head(3)\n",
    "logger.info(\"\\nTop 3 Models:\\n\" + top_3.to_string())\n",
    "\n",
    "top_3_file = os.path.join(output_folder, \"top_3_models.csv\")\n",
    "top_3.to_csv(top_3_file, index=False)\n",
    "logger.info(f\"Top 3 models saved to {top_3_file}\")\n",
    "\n",
    "# Save detailed trial logs\n",
    "selected_params_file = os.path.join(output_folder, \"selected_parameters.txt\")\n",
    "with open(selected_params_file, \"w\") as f:\n",
    "    for trial in study.trials:\n",
    "        f.write(f\"Trial {trial.number}: Meta Params: {trial.user_attrs['meta_params']}, Mean AUC: {trial.user_attrs['mean_auc']}, Fold AUCs: {trial.user_attrs['fold_aucs']}\\n\")\n",
    "logger.info(f\"Selected parameters and AUC scores saved to {selected_params_file}\")\n",
    "\n",
    "logger.info(f\"Optimization complete. Results saved in folder: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
