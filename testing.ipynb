{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install imbalanced-learn\n",
    "!pip install imbalanced-learn --quiet\n",
    "!pip install pandas --quiet\n",
    "!pip install matplotlib --quiet\n",
    "!pip install seaborn --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "!pip install xgboost --quiet\n",
    "!pip install lightgbm --quiet\n",
    "!pip install catboost --quiet\n",
    "!pip install optuna --quiet\n",
    "print(\"Installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing Libraries\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model Selection and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-saved training and validation sets\n",
    "X_train_resampled = pd.read_csv('X_train_resampled.csv')\n",
    "y_train_resampled = pd.read_csv('y_train_resampled.csv').squeeze()  # Squeeze to convert to Series if needed\n",
    "X_val = pd.read_csv('X_val.csv')\n",
    "y_val = pd.read_csv('y_val.csv').squeeze()\n",
    "\n",
    "# Loading test set\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "\n",
    "# Loading submission template\n",
    "submission_template = pd.read_csv('submission_template.csv')\n",
    "\n",
    "print(\"DataFrames loaded from CSV successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the model with new hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=7,\n",
    "    min_child_weight=1,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.7978109153629405,\n",
    "    scale_pos_weight=10,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the resampled training data\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "y_prob = xgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"XGBoost with Updated Hyperparameters\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Step 6: Run probability predictions on the test set\n",
    "test_probabilities = xgb_model.predict_proba(X_test)[:, 1]  # Select probability for the positive class (isFraud)\n",
    "\n",
    "# Step 7: Prepare submission DataFrame with probabilities\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities\n",
    "\n",
    "# Step 8: Save predictions to a CSV file\n",
    "submission.to_csv('best/submission_xgb_best.csv', index=False)\n",
    "\n",
    "print(\"Probability predictions saved to submission_xgb_best.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight=None, random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "y_prob = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Step 6: Run predictions on the test set\n",
    "test_probabilities = rf.predict_proba(X_test)[:, 1]  # Select probability for the positive class (isFraud)\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities  # Assign probabilities\n",
    "\n",
    "# Step 8: Save predictions to a CSV file\n",
    "submission.to_csv('best/submission_rfc_best.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to submission_rfc_best.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# params = {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cholesky', 'class_weight': None, 'max_iter': 1000, 'tol': 1e-4}\n",
    "\n",
    "params = {'solver': 'newton-cholesky', 'penalty': 'l2', 'C': 0.04783940335702436, 'tol': 1.3833218995442702e-05, 'max_iter': 631}\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42, **params)\n",
    "log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Validation predictions and evaluation\n",
    "y_pred = log_reg.predict(X_val)\n",
    "y_prob = log_reg.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val, y_prob)\n",
    "\n",
    "test_probabilities = log_reg.predict_proba(X_test)\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities[:, 1]  # Assuming 'isFraud' is the positive class\n",
    "\n",
    "# Save the submission file for each combination\n",
    "submission.to_csv(f'best/submission_best_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "    \n",
    "# params={'learning_rate': 0.05, 'iterations': 500, 'depth': 8, 'l2_leaf_reg': 5, 'bagging_temperature': 0.5, 'random_strength': 2, 'scale_pos_weight': 10}\n",
    "\n",
    "params = {'learning_rate': 0.14501102083693077, 'iterations': 751, 'depth': 8, 'l2_leaf_reg': 5.595512756503533, 'bagging_temperature': 1.0454087496215603, 'random_strength': 1.008663275116376, 'scale_pos_weight': 8.064297059289366, \n",
    "           'random_seed': 42, 'verbose': 0}\n",
    "# Initialize the CatBoost model with current parameters\n",
    "catboost_model = CatBoostClassifier(\n",
    "    **params,\n",
    "    eval_metric='AUC'\n",
    ")\n",
    "\n",
    "    # Fit the model on the resampled training data\n",
    "catboost_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Make predictions on the validation set\n",
    "y_pred = catboost_model.predict(X_val)\n",
    "y_prob = catboost_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"Parameters:\", params)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\\n\")\n",
    "\n",
    "# Step 6: Predict probabilities on the test set\n",
    "test_probabilities = catboost_model.predict_proba(X_test)\n",
    "\n",
    "# Step 7: Prepare submission DataFrame with probabilities for the positive class\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities[:, 1]  # Assuming 'isFraud' is the positive class\n",
    "\n",
    "# Step 8: Save predictions to a CSV file with a unique name for each parameter set\n",
    "submission.to_csv(f'best/submission_catboost_best.csv', index=False)\n",
    "print(\"DOne! , saved\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# params = {'learning_rate': 0.05, 'n_estimators': 500, 'max_depth': 15, 'num_leaves': 50, 'min_child_samples': 10,\n",
    " # 'subsample': 1.0, 'colsample_bytree': 0.6, 'reg_lambda': 5, 'reg_alpha': 0.1, 'scale_pos_weight': 10}\n",
    "params = {'learning_rate': 0.09906417236746058, 'n_estimators': 454, 'max_depth': 10, 'num_leaves': 46, \n",
    "          'min_child_samples': 47, 'subsample': 0.8592558986910852, 'colsample_bytree': 0.7443545915949523, \n",
    "          'reg_lambda': 1.7308107963855828, 'reg_alpha': 0.24840082175007047, 'scale_pos_weight': 2.458598065242119}\n",
    "\n",
    "# Initialize the LGBMClassifier with current parameters\n",
    "lgbm_model = LGBMClassifier(\n",
    "    **params,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the resampled training data\n",
    "lgbm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = lgbm_model.predict(X_val)\n",
    "y_prob = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Parameters:\", params)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\\n\")\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "test_probabilities = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities  # Save probabilities as predictions\n",
    "\n",
    "# Save predictions to a CSV file with a unique name for each parameter set\n",
    "submission.to_csv(f'best/submission_lgbm_best.csv', index=False)\n",
    "\n",
    "print(\"Probability predictions saved to submission_lgbm_best.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Combine models in a voting ensemble\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lgbm', lgbm_model),\n",
    "    ('catboost', catboost_model),\n",
    "    ('xgb', xgb_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit on the resampled training data\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = voting_clf.predict(X_val)\n",
    "y_prob = voting_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Voting Ensemble Model\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Predict on the test data using the voting model\n",
    "test_predictions = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('best/submission_voting_1.csv', index=False)\n",
    "print(\"Voting model submission file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Combine models in a voting ensemble\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', log_reg),\n",
    "    ('lgbm', lgbm_model),\n",
    "    ('catboost', catboost_model),\n",
    "    ('xgb', xgb_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit on the resampled training data\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = voting_clf.predict(X_val)\n",
    "y_prob = voting_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Voting Ensemble Model\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Predict on the test data using the voting model\n",
    "test_predictions = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('best/submission_voting_2.csv', index=False)\n",
    "print(\"Voting model submission file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Combine models in a voting ensemble\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', log_reg),\n",
    "    ('rf', rf),\n",
    "    ('lgbm', lgbm_model),\n",
    "    ('catboost', catboost_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit on the resampled training data\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = voting_clf.predict(X_val)\n",
    "y_prob = voting_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Voting Ensemble Model\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Predict on the test data using the voting model\n",
    "test_predictions = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities\n",
    "\n",
    "# Save the submission to a CSV file\n",
    "submission.to_csv('best/submission_voting_3.csv', index=False)\n",
    "print(\"Voting model submission file generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  StackingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('lgbm', lgbm_model),    # Pre-trained LightGBM\n",
    "    ('catboost', catboost_model),  # Pre-trained CatBoost\n",
    "]\n",
    "\n",
    "# Meta model\n",
    "meta_model = LogisticRegression(\n",
    "    solver='sag',\n",
    "    penalty='l2',\n",
    "    C=0.0016820949365318634,\n",
    "    tol=0.000417900469159281,\n",
    "    max_iter=900,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = stacking_clf.predict(X_val)\n",
    "y_prob = stacking_clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Stacking Model\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_prob):.4f}\")\n",
    "\n",
    "# Step 4: Predict on the test data using the stacking model\n",
    "# Run probability predictions on the test set using the stacking model\n",
    "test_probabilities = stacking_clf.predict_proba(X_test)[:, 1]  # Select probability for the positive class (isFraud)\n",
    "\n",
    "# Step 5: Prepare submission DataFrame with probabilities\n",
    "submission = submission_template.copy()\n",
    "submission['isFraud'] = test_probabilities\n",
    "\n",
    "# Step 6: Save the submission to a CSV file\n",
    "submission.to_csv('best/submission_stacking_best.csv', index=False)\n",
    "\n",
    "print(\"Probability predictions saved to submission_stacking.csv\")\n",
    "\n",
    "print(\"Stacking model submission file generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow tensorflow-gpu tensorflow-cpu\n",
    "!pip install tensorflow-cpu\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "\n",
    "# %%\n",
    "# Disable GPU Usage and Optimize TensorFlow for CPU\n",
    "\n",
    "import os\n",
    "\n",
    "# Disable all GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure TensorFlow to use all 36 CPU cores efficiently\n",
    "tf.config.threading.set_intra_op_parallelism_threads(36)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(36)\n",
    "\n",
    "# Verify TensorFlow is using CPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing Libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Model Selection and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Supervised Autoencoder Architecture\n",
    "\n",
    "# Define the size of the input\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# Input Layer\n",
    "input_layer = Input(shape=(input_dim,), name=\"input_layer\")\n",
    "\n",
    "# Encoder Layers with L2 regularization and LeakyReLU activation\n",
    "encoded = Dense(256, kernel_regularizer=l2(0.001))(input_layer)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "\n",
    "encoded = Dense(128, kernel_regularizer=l2(0.001))(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "\n",
    "encoded = Dense(64, kernel_regularizer=l2(0.001))(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "\n",
    "encoded = Dense(32, kernel_regularizer=l2(0.001))(encoded)\n",
    "encoded = LeakyReLU(alpha=0.1)(encoded)\n",
    "encoded = BatchNormalization()(encoded)\n",
    "encoded = Dropout(0.3)(encoded)\n",
    "\n",
    "# Bottleneck Layer\n",
    "bottleneck = Dense(16, activation=\"linear\", name=\"bottleneck\")(encoded)\n",
    "\n",
    "# Decoder Layers\n",
    "decoded = Dense(32, kernel_regularizer=l2(0.001))(bottleneck)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "decoded = Dropout(0.3)(decoded)\n",
    "\n",
    "decoded = Dense(64, kernel_regularizer=l2(0.001))(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "decoded = Dropout(0.3)(decoded)\n",
    "\n",
    "decoded = Dense(128, kernel_regularizer=l2(0.001))(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "decoded = Dropout(0.3)(decoded)\n",
    "\n",
    "decoded = Dense(256, kernel_regularizer=l2(0.001))(decoded)\n",
    "decoded = LeakyReLU(alpha=0.1)(decoded)\n",
    "decoded = BatchNormalization()(decoded)\n",
    "decoded = Dropout(0.3)(decoded)\n",
    "\n",
    "# Output Layer for Reconstruction\n",
    "reconstruction_output = Dense(input_dim, activation=\"linear\", name=\"reconstruction\")(\n",
    "    decoded\n",
    ")\n",
    "\n",
    "# Output Layer for Classification\n",
    "classification_output = Dense(1, activation=\"sigmoid\", name=\"classification\")(\n",
    "    bottleneck\n",
    ")\n",
    "\n",
    "# Combined Model with outputs as a list\n",
    "autoencoder_classifier = Model(\n",
    "    inputs=input_layer, outputs=[reconstruction_output, classification_output]\n",
    ")\n",
    "\n",
    "# Adjust optimizer with lower learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# Compile the model with adjusted loss weights and AUC metric\n",
    "autoencoder_classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=[\n",
    "        \"mse\",  # Reconstruction loss\n",
    "        \"binary_crossentropy\",  # Classification loss\n",
    "    ],\n",
    "    loss_weights=[\n",
    "        0.3,  # Weight for reconstruction loss\n",
    "        0.7,  # Weight for classification loss\n",
    "    ],\n",
    "    metrics=[\n",
    "        None,  # No metrics for reconstruction\n",
    "        [tf.keras.metrics.AUC(name=\"auc\")],  # Metrics for classification\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "autoencoder_classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sample weights for the classification output\n",
    "sample_weights_classification = compute_sample_weight(\n",
    "    class_weight=\"balanced\", y=y_train\n",
    ")\n",
    "\n",
    "# Create a list of sample weights matching the outputs\n",
    "sample_weight_list = [\n",
    "    np.ones(len(y_train)),  # Sample weights for reconstruction (all ones)\n",
    "    sample_weights_classification,  # Sample weights for classification\n",
    "]\n",
    "\n",
    "# Create sample weights for validation data\n",
    "sample_weight_val = [\n",
    "    np.ones(len(y_val)),  # Sample weights for reconstruction in validation\n",
    "    np.ones(len(y_val)),  # Sample weights for classification in validation\n",
    "]\n",
    "\n",
    "# Define early stopping to prevent overfitting, monitoring AUC\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_output_2_auc\",  # Adjusted to match the output name\n",
    "    mode=\"max\",\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# Define model checkpointing to save the model after every epoch\n",
    "checkpoint_filepath = \"models_checkpoints/model_checkpoint_epoch_{epoch:02d}.keras\"\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,  # Save the full model\n",
    "    monitor=\"val_output_2_auc\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=False,  # Save the model after every epoch\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Train the model with increased epochs and sample weights\n",
    "history = autoencoder_classifier.fit(\n",
    "    X_train_scaled,\n",
    "    [X_train_scaled, y_train_resampled],\n",
    "    sample_weight=sample_weight_list,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_data=(\n",
    "        X_val_scaled,\n",
    "        [X_val_scaled, y_val],\n",
    "        sample_weight_val,  # Include sample weights for validation data\n",
    "    ),\n",
    "    callbacks=[early_stopping, model_checkpoint_callback],\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "# Predict on validation set\n",
    "predictions = autoencoder_classifier.predict(X_val_scaled)\n",
    "reconstruction_pred = predictions[0]\n",
    "y_val_pred_prob = predictions[1]\n",
    "\n",
    "# Evaluate the performance using probabilities\n",
    "print(\"Classification Report on Validation Set (Threshold = 0.5):\")\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_val, y_val_pred_prob):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define custom objects dictionary\n",
    "custom_objects = {\"LeakyReLU\": tf.keras.layers.LeakyReLU, \"AUC\": tf.keras.metrics.AUC}\n",
    "\n",
    "# Directory containing the saved models\n",
    "model_dir = \".\"  # Current directory, adjust if needed\n",
    "\n",
    "# Lists to store metrics\n",
    "epochs = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_aucs = []\n",
    "val_aucs = []\n",
    "\n",
    "model_dir = \"/home/vdupati1/models_checkpoints\"  # Replace with the actual path to your subfolder if different\n",
    "\n",
    "# Get list of model files sorted by epoch\n",
    "model_files = sorted(\n",
    "    [\n",
    "        f\n",
    "        for f in os.listdir(model_dir)\n",
    "        if f.startswith(\"model_checkpoint_epoch_\") and f.endswith(\".keras\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "for model_file in model_files:\n",
    "    # Extract epoch number from the filename\n",
    "    epoch_num = int(model_file.split(\"_\")[-1].split(\".\")[0])\n",
    "    epochs.append(epoch_num)\n",
    "\n",
    "    # Load the model\n",
    "    # print(model_file)\n",
    "    model_file = \"/home/vdupati1/models_checkpoints/\" + model_file\n",
    "    model = load_model(model_file, custom_objects=custom_objects)\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_metrics = model.evaluate(\n",
    "        X_val_scaled, [X_val_scaled, y_val], sample_weight=sample_weight_val, verbose=0\n",
    "    )\n",
    "    val_losses.append(val_metrics[0])  # Total loss\n",
    "    val_aucs.append(val_metrics[-1])  # AUC is the last metric\n",
    "\n",
    "    # Clear the model from memory\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Combine metrics into a DataFrame\n",
    "metrics_df = pd.DataFrame(\n",
    "    {\"Epoch\": epochs, \"Validation Loss\": val_losses, \"Validation AUC\": val_aucs}\n",
    ")\n",
    "\n",
    "# Sort by Epoch\n",
    "metrics_df.sort_values(\"Epoch\", inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Validation AUC\n",
    "plt.plot(metrics_df[\"Epoch\"], metrics_df[\"Validation AUC\"], label=\"Validation AUC\")\n",
    "\n",
    "# Optional: Plot Training AUC if collected\n",
    "# plt.plot(metrics_df['Epoch'], metrics_df['Training AUC'], label='Training AUC')\n",
    "\n",
    "plt.title(\"Model AUC over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Similarly, you can plot Validation Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(metrics_df[\"Epoch\"], metrics_df[\"Validation Loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test Data\n",
    "\n",
    "X_test = X_test.loc[:, X_test.columns != \"TransactionID\"]\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on test data\n",
    "predictions_test = autoencoder_classifier.predict(X_test_scaled)\n",
    "y_test_pred_prob = predictions_test[1]\n",
    "\n",
    "# Use the predicted probabilities directly for submission\n",
    "test_predictions = y_test_pred_prob.flatten()\n",
    "\n",
    "# Ensure the probabilities are within [0, 1]\n",
    "test_predictions = np.clip(test_predictions, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Submission\n",
    "\n",
    "submission_autoencoder_classifier = submission_template.copy()\n",
    "submission_autoencoder_classifier[\"isFraud\"] = test_predictions\n",
    "\n",
    "submission_autoencoder_classifier.to_csv(\n",
    "    \"submission_autoencoder_classifier_updated.csv\", index=False\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Updated autoencoder-based classifier submission file with probabilities generated successfully!\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
